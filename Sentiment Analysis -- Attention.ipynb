{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import bz2\n",
    "import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"./data/amazonreviews/train.ft.txt.bz2\"\n",
    "test_file = \"./data/amazonreviews/test.ft.txt.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_reviews_labels(lines):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for review in tqdm.tqdm(lines):\n",
    "        rev = review_to_x(review)\n",
    "        label = review_to_y(review)\n",
    "        reviews.append(rev[:512])\n",
    "        labels.append(label)\n",
    "    return reviews, labels\n",
    "        \n",
    "        \n",
    "def review_to_x(review):\n",
    "    review = review.split(\" \", 1)[1][:-1].lower()\n",
    "    review = re.sub(\"\\d\",\"0\",review)\n",
    "    \n",
    "    if \"www.\" in review or \"http\" in review or \"https:\" in review or \".com\" in review:\n",
    "        review = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", review)\n",
    "    return review\n",
    "\n",
    "\n",
    "def review_to_y(review):\n",
    "    return [1,0] if review.split(\" \")[0] == \"__label__1\" else [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = bz2.BZ2File(train_file)\n",
    "test_file = bz2.BZ2File(test_file)\n",
    "\n",
    "train_lines = train_file.readlines()\n",
    "test_lines = test_file.readlines()\n",
    "\n",
    "train_lines = [x.decode(\"utf-8\") for x in train_lines]\n",
    "test_lines = [x.decode(\"utf-8\") for x in test_lines]\n",
    "\n",
    "reviews_train, y_train = split_reviews_labels(train_lines)\n",
    "reviews_test, y_test = split_reviews_labels(test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train, y_train = split_reviews_labels(train_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train, y_train = shuffle(reviews_train, y_train)\n",
    "reviews_test, y_test = shuffle(reviews_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 256 #8192\n",
    "maxlen = 128\n",
    "embed_size = 64\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(reviews_train)\n",
    "\n",
    "x_train = tokenizer.text_to_sequences(reviews_train)\n",
    "x_test = tokenizer.text_to_sequences(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWeightedAverage(Layer):\n",
    "    \"\"\"\n",
    "    Computes a weighted average of the different channels across timesteps.\n",
    "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, return_attention=False, **kwargs):\n",
    "        self.init = initializers.get('uniform')\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'return_attention': self.return_attention,\n",
    "        }\n",
    "        base_config = super(AttentionWeightedAverage, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=self.init)\n",
    "        self.trainable_weights = [self.W]\n",
    "        super(AttentionWeightedAverage, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # computes a probability distribution over the timesteps\n",
    "        # uses 'max trick' for numerical stability\n",
    "        # reshape is done to avoid issue with Tensorflow\n",
    "        # and 1-dimensional weights\n",
    "        logits = K.dot(x, self.W)\n",
    "        x_shape = K.shape(x)\n",
    "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
    "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
    "\n",
    "        # masked timesteps have zero weight\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            ai = ai * mask\n",
    "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
    "        weighted_input = x * K.expand_dims(att_weights)\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "        if self.return_attention:\n",
    "            return [result, att_weights]\n",
    "        return result\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return self.compute_output_shape(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[2]\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
    "        return (input_shape[0], output_len)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        if isinstance(input_mask, list):\n",
    "            return [None] * len(input_mask)\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_output = False\n",
    "embed_dropout_rate = 0\n",
    "final_dropout_rate = 0\n",
    "embed_l2 = 1e-6\n",
    "return_attention = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(maxlen, feature_output = False, embed_dropout_rate=0,\n",
    "             final_dropout_rate=0, embed_l2=1e-6, return_attention=False):\n",
    "    input = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size)(input)\n",
    "    x = Activation(\"tanh\")(x)\n",
    "    lstm_0_output = Bidirectional(LSTM(512, return_sequences=True), name=\"bi_lstm_0\")(x)\n",
    "    lstm_1_output = Bidirectional(LSTM(512, return_sequences=True), name=\"bi_lstm_1\")(lstm_0_output)\n",
    "    x = concatenate([lstm_1_output, lstm_0_output, x])\n",
    "\n",
    "    # if return_attention is True in AttentionWeightedAverage, an additional tensor\n",
    "    # representing the weight at each timestep is returned\n",
    "    weights = None\n",
    "    x = AttentionWeightedAverage(name='attlayer', return_attention=return_attention)(x)\n",
    "    if return_attention:\n",
    "        x, weights = x\n",
    "\n",
    "    if not feature_output:\n",
    "        # output class probabilities\n",
    "        if final_dropout_rate != 0:\n",
    "            x = Dropout(final_dropout_rate)(x)\n",
    "    else:\n",
    "        # output penultimate feature vector\n",
    "        outputs = [x]\n",
    "\n",
    "    if return_attention:\n",
    "        # add the attention weights to the outputs if required\n",
    "        outputs.append(weights)\n",
    "\n",
    "    model = Model(inputs=[model_input], outputs=outputs, name=\"Sentiment Model\")\n",
    "    model.complie(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(maxlen, return_attention=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=2048, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"sentiment_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = get_model(maxlen, return_attension=True)\n",
    "model2.load_weights(\"sentiment_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML as html_print\n",
    "\n",
    "def amplify_difference(x):\n",
    "    x = (x - np.mean(x))*100\n",
    "    return (np.exp(x) / np.sum(np.exp(x), axis=0) * 100).astype(int)\n",
    "\n",
    "\n",
    "def color_print(s, strength, sentiment=None):\n",
    "    h = min(100 - sentiment[0], sentiment[1])\n",
    "    return \"<text style='color:white; background-color:hsl({}, 100%, {}%)'>{} </text>\".format(h, 50-strength, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [\"This page is awesome\"]\n",
    "\n",
    "inp = tokenizer.texts_to_sequence(sent)\n",
    "out, attn = model2.predict(inp)\n",
    "\n",
    "temp_text = tokenizer.sequence_to_texts(inp)\n",
    "\n",
    "strength = rescale(attn[0].tolist()[:len(seq[0])])\n",
    "\n",
    "for i in range(len(tmp_text[0].split())):\n",
    "    string += cstr(tmp_text[0].split()[i], strength[i], out[0])\n",
    "    \n",
    "html_print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
